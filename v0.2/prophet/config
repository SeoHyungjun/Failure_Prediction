# DataCollect section is related in Framework.
# such as data collect buf size etc..


# ======================================================== #
# ML_Process sections apply to trainer and predictor.
# It can use more than one algorithm.
# ml_name must be machine learning class name
# dir_project means root dir that contain input and output dir
# dir input means root dir that contain input data
[ML_Process]
ml_num = 2
ml_names = K_Means, ANN
window_size = 10
dir_project = ./FP_project
dir_input = input
[Trainer]
collect_port = 
[Predictor]
collect_port =

# Each algorithm has different parameters.
# Each section contains the data transform functions that will 
# work before the algorithm is executed.
# Each session defines parameters for the machine learnings to be run.
# The machine learning name is either the name of the machine learning supported
# by the framework or the name of the machine learning you have implemented.
# At this time, the name of the machine learning must be the same as
# the class name of the implemented machine learning.
#
# The parameters may vary depending on the machine learning.
# At the bottom of this sections there are the default parameter
# settings for each machine learning. You must use or modify it.
#
# Each session refers to the order that will be used to learn
# and run the machine learnings that will work in the framework.
# If you are using two machine learnings, set the enable entry
# in the FIRST_MODEL and SECOND_MODEL sections to true
# and set the rest to false.

[1st_ML]
enable = true
ml_name = K_Means
ml_dir = K_Means
num_centroids = 4
trained_centroid_file = centriod.csv
# output config
ml_save_tag = ml
project_dirpath = ./FP_project
trained_centroid_outfile = centroid.csv
# machine learning model
centroid_num = 4
max_iters = 1000
# [output directory]
#INPUT_DIR = "input"
#TRAINED_MODEL_DIR = "trained_model"
#SUMMARY_DIR = "summary"
#SUMMARY_TRAIN_DIR = "train"
#SUMMARY_VALIDATION_DIR = "validation"

# [ANN]
# ANN_MODEL_DIR = "ANN"
# ANN_MODEL_NAME = "ANN"
# ANN_NODES_NUM = [8,5]
## regularization : dropout_keep_prob, l2_reg_lambda(when not applied, each value are 1.0, 0.0)
# ANN_DROPOUT_KEEP_PROB = 0.5
# ANN_L2_REG_LAMBDA = 0.0
# ANN_VALIDATION_SAMPLE_PERCENTAGE = 0.1
# ANN_BATCH_SIZE = 32
# ANN_EPOCHS_NUM = 1
# ANN_VALIDATION_INTERVAL = 2000
[2nd_ML]
enable = false
ml_name = ANN
ml_dir = ANN
num_nodes = "10,7"
dropout_keep_prob = 0.5
l2_reg_lambda = 0.0
validation_sample_percentage = 0.1
batch_size = 32
num_epochs = 2
validation_interval = 2000

[3rd_ML]
enable = false
ml_name = ml1
param1 = 122
param2 = parazz
param3 = 2222

[4th_ML]
enable = false
ml_name =
arg1 =
arg2 =

# Below are the default parameters for the models supported by the framework.

# K_Means Clustering Default Parameters
# trained_centroid_file : file path to save centroids after clustering.
#
# [Xth_MODEL]
# enable = true
# model_name = K_Means
# model_dir = K_Means
# num_centroids = 4
# max_iters = 1000
# trained_centroid_file =
#

# Artificial Neural Network Default Parameters
# dropout_keep_prob, l2_leg_lambda : prevent from overfitting.
# validation_sample_percentage : ratio of validation data in learning data
# batch_size : size of data to be used for learning at one time.
# num_epochs : The number of learning times for the same data
# validation_interval : Interval to evaluate the model learned to date with validation data
#
# [Xth_MODEL]
# enable = true
# model_name = ANN
# model_dir = ANN
# num_nodes = "10,7"
# dropout_keep_prob = 0.5
# l2_reg_lambda = 0.0
# validation_sample_percentage = 0.1
# batch_size = 32
# num_epochs = 2
# validation_interval = 2000
#

# ======================================================== #
# In operations section, enter the operation sequence.
#
# In the "ML_PROCESS SECTION" above, you can define the order of
# model learning operations in the order of the input models.
# if Model_names = model1, model2,
# The first_model entry defines the order of operations for model1, and
# the second_model entry defines the order of operations for model2.
# The steps of each operation are separated by ','.
#
# Below is an example of writing the operation sequence.
#
# first_model = TI:"data_path1", DT:"1col_del":"2", T:"ANN", DT:"transpose", TO:"output_path1"
# second_model = TI:"data_path2", R:"first_model", DT:"transpose", T:"CNN"
#
# The above example defines a sequence of operations that
# learns two models to create a predictive model.
# For data transform functions, the arguments can be multiple,
# such as :"arg1":"arg2".
#
# Option "TO" is the path where the learned model is saved.
# If not set, it will be saved in the default path.
#
# All elements must be enclosed in double quotes.
# (Data path, model name, data transformation function and arguments, etc.)
#
# 'create' : Create machine learning model
# 'restore' : Restore machine learning model
# 'Train'  : Train machine learning model
# 'Run'  : Run machine learning model(Predict)
#
# 'O' : Output directory path
# 'DS' : Data selection method
# 'DP' : Data preprocessing method
# 'DT' : Data transform method

[Train_Operations]
1st_ML = create, train
2nd_ML = create, train

[Predict_Operations]
# predict data source can be pipe...
1st_ML = create, run
2nd_ML = create, run
#1st_ML = C:"/root/input", R, O:"/root/dir"
#2nd_ML = C:"/root/input", R, O:"/root/dir"
#first_ml = TI:"train_data", T:"first_ml", M:"transpose", TO:"output_path"
#second_ml = TI:"train_data", M:"deduplicates":"1":"3", R:"first_ml", T:"second_ml", M:"transpose"
#predict_operations = PI:"predict_data", DT:"deduplicates":"1":"2", R:"first_ml", DT:"1col_del", R:"second_ml"
